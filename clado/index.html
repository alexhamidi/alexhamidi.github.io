<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="apple-touch-icon" sizes="180x180" href="../favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="../favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="../favicon/favicon-16x16.png">
  <link rel="icon" href="../favicon/favicon.ico">
  <link rel="manifest" href="../favicon/site.webmanifest">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$']],
        displayMath: [['$$', '$$'], ['\[', '\]']]
      }
    };
  </script>
  <title>creating a new query language @ clado - Alex Hamidi</title>
</head>

<body class="flex flex-col items-center text-gray-900 font-mono overflow-x-hidden bg-[#fcfcfa] color-[#121212]">

  <div class="flex flex-col gap-8 max-w-[700px] px-[20px] mb-12">

    <div class="flex items-center justify-between mt-8 mb-4">
      <a href="/" class="text-sm text-gray-600 hover:text-gray-900 underline">← back to home</a>
      <div class="text-xs text-gray-500">August 2025</div>
    </div>

    <article class="blog-content text-sm">
      <h1 class="text-3xl font-bold mb-6">creating a new query language</h1>
<h3 class="text-xl font-semibold mt-8 mb-4">Background</h3>
<p class="mb-4 leading-relaxed">A few months ago, I joined <a href="https://clado.ai/" class="underline text-gray-900 transition-all duration-500 hover:text-gray-50 hover:bg-gray-700 px-0.5">Clado</a> as a software engineer. My internship has since ended, but I wanted to share a bit about one of my contributions to clado’s people search engine, which performs <a href="https://pbs.twimg.com/media/GwLWi2lWoAAGpOc?format=jpg&name=medium" class="underline text-gray-900 transition-all duration-500 hover:text-gray-50 hover:bg-gray-700 px-0.5">better than all competitors</a> on <a href="https://pearch.ai/" class="underline text-gray-900 transition-all duration-500 hover:text-gray-50 hover:bg-gray-700 px-0.5">pearch.ai’</a>s sourcing <a href="https://arxiv.org/pdf/2504.02463" class="underline text-gray-900 transition-all duration-500 hover:text-gray-50 hover:bg-gray-700 px-0.5">benchmark</a>.</p>
<p class="mb-4 leading-relaxed">As a primer: Our search is criteria based, and users can search through 100+ fields across 1B+ profiles in a single query. We achieve this at scale by decomposing the search problem into two subproblems:</p>
<ol class="list-decimal pl-6 mb-4 space-y-2"><li>generating a database query based on the user’s input</li><li>filtering returned profiles in parallel using large language models.</li></ol>
<p class="mb-4 leading-relaxed">This will be about the first part</p>
<p class="mb-4 leading-relaxed">Around 1 week in, we migrated our database from a MySQL to OpenSearch. After running a set of evals, I found that most open models (in the 18b-32b parameter range) struggled to generate valid OpenSearch queries, primarily because of how much more verbose and complex the syntax was relative SQL.</p>
<p class="mb-4 leading-relaxed">For reference, here is an SQL query corresponding to the search “Find me software engineers in SF”:</p>
<pre class="bg-gray-50 border border-gray-200 rounded-lg p-4 overflow-x-auto my-4 text-sm"><code class="language-sql">SELECT *
FROM people
WHERE 
  ( -- this is "criteria 1"
    location LIKE '%SF%'
    OR location LIKE '%San Francisco%' 
  )
  AND ( -- this is "criteria 2"
    current_company_title LIKE '%Software Engineer%'
    OR past_company_title LIKE '%Software Engineer%'
  );
</code></pre>
<p class="mb-4 leading-relaxed">And here is the OpenSearch equivalent:</p>
<pre class="bg-gray-50 border border-gray-200 rounded-lg p-4 overflow-x-auto my-4 text-sm"><code class="language-json">{
  "query": {
    "bool": {
      "must": [
        {
          "bool": { // this is "criteria 1"
            "should": [
              { "match_phrase": { "location": "SF" } },
              { "match_phrase": { "location": "San Francisco" } }
            ],
            "minimum_should_match": 1
          }
        }
      ],
      // this is "criteria 1"
      "should": [
        { "match_phrase": { "current_company_title": "Software Engineer" } },
        { "match_phrase": { "past_company_title": "Software Engineer" } }
      ],
      "minimum_should_match": 1
    }
  }
}
</code></pre>
<p class="mb-4 leading-relaxed">OpenSearch’s 3x more tokens on average also translated directly to 3x higher inference costs (!).  With these problems in mind, I realized something exciting: I could create a *completely new* *language* that was optimized for our criteria-based searches, and then interpret that to any query DSL, whether it be SQL, OpenSearch, etc.</p>
<p class="mb-4 leading-relaxed">The new language had to have a few traits:</p>
<ol class="list-decimal pl-6 mb-4 space-y-2"><li>*maximally* *expressive*, meaning it could represent any possible query a user might make to Clado</li><li>*maximally concise -* to reduce token spend, inference time, and failure probability</li></ol>
<p class="mb-4 leading-relaxed">I eventually arrived at a language that takes the following form:</p>
<pre class="bg-gray-50 border border-gray-200 rounded-lg p-4 overflow-x-auto my-4 text-sm"><code class="language-json">[
	("location", "contains", ["SF", "San Francisco"]),
	(["current_company_title", "past_company_title"], "contains", "Software Engineer")
]
</code></pre>
<p class="mb-4 leading-relaxed">This is 1/2 the token length of SQL:</p>
<table class="min-w-full border-collapse border border-gray-300 my-6 text-sm">
  <thead class="bg-gray-50">
    <tr>
      <th class="border border-gray-300 px-4 py-2 font-semibold text-left">Language</th>
      <th class="border border-gray-300 px-4 py-2 font-semibold text-left">Average Tok Length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td class="border border-gray-300 px-4 py-2 text-left">SQL</td>
      <td class="border border-gray-300 px-4 py-2 text-left">151</td>
    </tr>
    <tr>
      <td class="border border-gray-300 px-4 py-2 text-left">OpenSearch</td>
      <td class="border border-gray-300 px-4 py-2 text-left">459</td>
    </tr>
    <tr>
      <td class="border border-gray-300 px-4 py-2 text-left"><strong>New DSL</strong></td>
      <td class="border border-gray-300 px-4 py-2 text-left"><strong>62</strong></td>
    </tr>
  </tbody>
</table>
Using this new language would mean cheaper and faster generation. We would also no longer need to retrain models every time we switched to a new query language.
<p class="mb-4 leading-relaxed">But there was one potential problem - the language is not in the training corpus of the LLM, which, presumably, would make the LLM less effective at generating queries. This is precisely the type of problem that can be solved with LLM fine-tuning</p>
<h3 class="text-xl font-semibold mt-8 mb-4">Fine-tuning:</h3>
<p class="mb-4 leading-relaxed">Fine-tuning is a method used to adapt LLMs to narrow tasks. The two most common types are:</p>
<ul class="list-disc pl-6 mb-4 space-y-2"><li>Supervised Fine Tuning (SFT) - you provide valid input/output pairs, which the model learns from</li><li>Reinforcement Learning (RL) - you provide a function that scores the LLM’s outputs, which the model learns from</li></ul>
<p class="mb-4 leading-relaxed">We tried to use SFT by running our task through a stronger model, Openai o3, and distilling those ouputs to Qwen-32b, with disappointing results:</p>
<img src="../public/sft.png" alt="SFT Results" class="max-w-full h-auto my-6 rounded-lg border border-gray-200">
<p class="mb-4 leading-relaxed">SFT alone plateaued because the teacher model didn’t have a robust understanding of the task, and struggled to generate valid DSL that represented the user’s intent (despite how hard we tried to prompt it to).</p>
<p class="mb-4 leading-relaxed">Luckily, we could use RL to directly optimize for the metrics we cared about - result quantity and quality. Given that RL will converge towards an optimal policy, the problem becomes defining a reward function. We landed on:</p>
<div class=" my-6 bg-gray-50 p-4 border border-gray-200 rounded-lg text-center">$
R(q,p) = w_q \cdot R_{\text{quality}}(q,p) + w_u \cdot R_{\text{quantity}}(q,p) 
$</div>
<p class="mb-4 leading-relaxed">where <span class="math-inline">$q$</span> is the user’s query, <span class="math-inline">$d$</span> is the LLM’s DSL program, and <span class="math-inline">$D = \text{search}(p)$</span>  is set of profiles returned after executing the database query</p>
<p class="mb-4 leading-relaxed"><strong>Quality Reward</strong></p>
<p class="mb-4 leading-relaxed">To measure result quality, we used LLM-as-a-judge. We define the function:</p>
<div class=" my-6 bg-gray-50 p-4 border border-gray-200 rounded-lg text-center">$
\text{judge}(q, d) \in \{2,1,0\}
$</div>
<p class="mb-4 leading-relaxed">to judge how well the document <span class="math-inline">$d$</span> matches the query <span class="math-inline">$q$</span>. The quality function is thus defined as the following:</p>
<div class=" my-6 bg-gray-50 p-4 border border-gray-200 rounded-lg text-center">$
 R_{\text{quality}}(q,D) = \frac{1}{|D|} \sum_{d \in D}  \cdot \frac{ \text{judge}(q,d) }{3}
$</div>
<p class="mb-4 leading-relaxed">Since quality of the results is the most important, we define:</p>
<div class=" my-6 bg-gray-50 p-4 border border-gray-200 rounded-lg text-center">$
w_{\text{quantity}} =0.7
$</div>
<p class="mb-4 leading-relaxed"><strong>Quantity Reward</strong></p>
<p class="mb-4 leading-relaxed">We used a quantity scoring function combined with LLM-as-a-judge to score returned scores.</p>
<div class=" my-6 bg-gray-50 p-4 border border-gray-200 rounded-lg text-center">$
R_{\text{quantity}} = \tanh\!\left(\frac{2|D_{\text{}}|}{E[q]}\right)
$</div>
<p class="mb-4 leading-relaxed">Where <span class="math-inline">$E[q]$</span> is an LLM’s expected number of profiles returned given the user query <span class="math-inline">$q$</span>.</p>
<div id="tanh-graph" class="my-8 bg-gray-50 p-6 rounded-lg border border-gray-200"><div class="text-center mb-4 text-sm font-semibold text-gray-700">Score VS Quantity as Expected Quantity Increases</div><div class="mb-4 flex items-center justify-center gap-4"><label class="text-sm font-medium text-gray-600">E(q) = </label><input type="range" id="n-slider" min="1" max="100" value="10" step="1" class="w-48 accent-gray-800"><span id="n-value" class="text-sm font-mono bg-white px-2 py-1 rounded border">10</span></div><div id="plot-container" style="height: 350px;" class="bg-white rounded border"></div></div>
<animation that shows what happens as you move E[q]>
<p class="mb-4 leading-relaxed"><strong>Training</strong></p>
<p class="mb-4 leading-relaxed">We trained the model with group-relative optimization using <a href="https://github.com/OpenPipe/ART" class="underline text-gray-900 transition-all duration-500 hover:text-gray-50 hover:bg-gray-700 px-0.5">ART</a>. For each query, we sampled <span class="math-inline">$G=4$</span> candidate outputs, parsed them into DSL, executed against an OpenSearch index of ~1B profiles. Each candidate output was scored with the abovecomposite reward.</p>
<p class="mb-4 leading-relaxed">Relative advantages were computed as:</p>
<div class=" my-6 bg-gray-50 p-4 border border-gray-200 rounded-lg text-center">$
A_i = R_i - \frac{1}{G} \sum_{j=1}^G R_j 
$</div>
<p class="mb-4 leading-relaxed">and used for PPO-style updates through ART. Training ran for 5k steps with 3–4 rollouts per step, cosine-decayed learning rates, and batch judging across 12 queries at a time.</p>
<p class="mb-4 leading-relaxed"><strong>Results</strong></p>
<p class="mb-4 leading-relaxed">Our final fine tuned model achieved 0.93 on eval set relative to 0.45 when we started. Plus, the model output valid DSL 100% of the time, and it was 3x faster and 6x cheaper than OpenSearch.</p>
<h3 class="text-xl font-semibold mt-8 mb-4">Reflection</h3>
<p class="mb-4 leading-relaxed">I had a lot of fun with this, and plan to continue experimenting with fine tuning in different domains.</p>
<p class="mb-4 leading-relaxed">My favorite result is that, as long as your reward function is aligned with your expectations there, is a decent chance your fine-tuned model will perform well.</p>
<p class="mb-4 leading-relaxed">And fine-tuning is now easier than ever - nothing here required more than 200 lines of code, and OpenAI even offers a <a href="https://platform.openai.com/finetune" class="underline text-gray-900 transition-all duration-500 hover:text-gray-50 hover:bg-gray-700 px-0.5">no-code platform</a> that makes it possible to fine tune their models.</p>
    </article>

    <div class="flex items-center justify-between mt-8 pt-8 border-t border-gray-200">
      <div class="text-sm text-gray-600">
        Written by <a href="/" class="underline hover:text-gray-900">Alex Hamidi</a>
      </div>
      <div class="flex gap-4 text-sm">
        <a href="https://twitter.com/ahamidi_" class="text-gray-600 hover:text-gray-900 underline">Twitter</a>
        <a href="https://github.com/alexhamidi/" class="text-gray-600 hover:text-gray-900 underline">GitHub</a>
      </div>
    </div>

  </div>

  <script>
    // Initialize the tanh graph if the element exists
    document.addEventListener('DOMContentLoaded', function() {
      const plotContainer = document.getElementById('plot-container');
      const slider = document.getElementById('n-slider');
      const nValue = document.getElementById('n-value');
      
      if (plotContainer && slider && nValue) {
        function updateGraph() {
          const n = parseFloat(slider.value);
          nValue.textContent = n;
          
          // Generate data points for x > 0
          const x = [];
          const y = [];
          for (let i = 0.1; i <= 100; i += 0.1) {
            x.push(i);
            y.push(Math.tanh(2 * i / n));
          }
          
          const trace = {
            x: x,
            y: y,
            type: 'scatter',
            mode: 'lines',
            name: `n = ${n}`,
            line: {
              color: '#000000',
              width: 3
            },
            hovertemplate: '|D|: %{x:.1f}<br>score: %{y:.3f}<extra></extra>'
          };
          
          const layout = {
            xaxis: {
              title: { text: '|D|', font: { size: 14, family: 'ui-monospace, monospace' } },
              range: [0, 100],
              gridcolor: '#e5e7eb',
              gridwidth: 1,
              zeroline: true,
              zerolinecolor: '#9ca3af',
              zerolinewidth: 2
            },
            yaxis: {
              title: { text: 'score', font: { size: 14, family: 'ui-monospace, monospace' } },
              range: [0, 1.1],
              gridcolor: '#e5e7eb',
              gridwidth: 1,
              zeroline: true,
              zerolinecolor: '#9ca3af',
              zerolinewidth: 1
            },
            plot_bgcolor: '#ffffff',
            paper_bgcolor: '#ffffff',
            font: { family: 'ui-monospace, monospace', size: 12, color: '#374151' },
            margin: { t: 20, r: 30, b: 50, l: 60 },
            showlegend: false
          };
          
          const config = {
            responsive: true,
            displayModeBar: false
          };
          
          Plotly.newPlot(plotContainer, [trace], layout, config);
        }
        
        // Initial plot
        updateGraph();
        
        // Update on slider change with smooth animation
        slider.addEventListener('input', updateGraph);
      }
    });
  </script>

</body>

</html>